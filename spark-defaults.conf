# Spark Configuration for Recommendation System
# Ten plik konfiguruje Spark dla optimal performance w naszym use case

# Basic Spark settings
spark.app.name                     recommendation_system_spark
spark.master                       local[*]
spark.sql.adaptive.enabled         true
spark.sql.adaptive.coalescePartitions.enabled  true
spark.serializer                   org.apache.spark.serializer.KryoSerializer

# Memory settings
spark.driver.memory                 2g
spark.executor.memory               2g
spark.driver.maxResultSize          1g

# Performance optimizations
spark.sql.execution.arrow.pyspark.enabled  true
spark.sql.adaptive.skewJoin.enabled        true
spark.sql.adaptive.localShuffleReader.enabled  true

# Event logging (for Spark History Server)
spark.eventLog.enabled              true
spark.eventLog.dir                  /tmp/spark-events

# UI and monitoring
spark.ui.port                       4040
spark.ui.enabled                    true

# MLlib settings
spark.ml.cache.enabled              true

# Optimize for recommendation workloads
spark.default.parallelism           4
spark.sql.shuffle.partitions        200

# Memory fractions
spark.executor.memoryFraction       0.8
spark.storage.memoryFraction        0.5

# Garbage collection
spark.executor.extraJavaOptions     -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions
spark.driver.extraJavaOptions       -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions
