Projekt: System rekomendacji produkt√≥w na podstawie cech tekstowych (opis, kategoria produktu) oraz wizualnych (wyglƒÖd)


Narzƒôdzia, kt√≥re ju≈º zosta≈Çy zaimplementowane:
    ‚Ä¢ LLM - generowanie embedding√≥w tekstowych, odpowiedzi dla klienta
    ‚Ä¢ langchain/langgraph - stworzenie agenta, kt√≥ry integruje r√≥≈ºne komponenty systemu rekomendacji
    ‚Ä¢ pytorch - model do computer vision ‚Äì docelowo wytrenowanie w≈Çasnej sieci neuronowej do ekstracji cech wizualnych z obraz√≥w produkt√≥w
    ‚Ä¢ bazy danych SQL - przechowywanie danych


Narzƒôdzia, kt√≥re jeszcze zostanƒÖ zaimplementowane:
    ‚Ä¢ RAG - stworzenie bazy wiedzy dla LLM - bardzo prosty tylko po to, ≈ºeby nauczyƒá siƒô implementacji
    ‚Ä¢ apache airflow - automatyzacja i harmonogramowanie zada≈Ñ
    ‚Ä¢ pyspark - przetwarzanie du≈ºych zbior√≥w danych
    ‚Ä¢ docker - konteneryzacja - dockerfile dla streamlit i dla API, utworzenie docker compose
    ‚Ä¢ kubernetes - zarzƒÖdzanie i monitorowanie kontener√≥w
    ‚Ä¢ prometheus - automatyczne zbieranie metryk z aplikacji i kubernetesa
    ‚Ä¢ grafana - wizualizacja metryk, tworzenie metryk zebranych przez prometheusa
    ‚Ä¢ MLflow - ≈õledzenie eksperyment√≥w, zapisywanie modeli podczas trenowania


    1. Integracja Retrieval-Augmented Generation (RAG)
       Opis: Wdro≈ºenie mechanizmu RAG, aby wzbogaciƒá proces rekomendacji o wiedzƒô zewnƒôtrznƒÖ. Stworzymy bazƒô wiedzy o produktach i wykorzystamy RAG do wyszukiwania relewantnych informacji na podstawie zapyta≈Ñ u≈ºytkownika. Pozwoli to na generowanie bardziej informatywnych i r√≥≈ºnorodnych rekomendacji, wykraczajƒÖcych poza proste podobie≈Ñstwo.
       Narzƒôdzia: LangChain RAG, baza danych wektorowych ChromaDB, baza wiedzy o produktach (opisy, recenzje, specyfikacje)

    2. Automatyzacja Potoku Danych z Apache Airflow
       Opis: Automatyzacja potoku przetwarzania danych, obejmujƒÖcego ≈Çadowanie danych, preprocessing, generowanie embedding√≥w i trenowanie modeli, przy u≈ºyciu Apache Airflow. Stworzymy DAG-i Airflow do planowania i automatyzacji potoku danych, zapewniajƒÖc aktualno≈õƒá danych, aktualizacje modeli i stabilno≈õƒá systemu.

    3. Przetwarzanie Du≈ºych Danych z PySpark
       Opis: Skalowanie mo≈ºliwo≈õci przetwarzania danych poprzez wykorzystanie PySpark do efektywnej obs≈Çugi du≈ºych zbior√≥w danych. Migracja zada≈Ñ przetwarzania danych (np. obliczanie macierzy podobie≈Ñstwa, generowanie embedding√≥w dla du≈ºych katalog√≥w produkt√≥w) do PySpark w celu rozproszonego przetwarzania i skalowalno≈õci.

    4. Konteneryzacja z Docker
       Opis: Konteneryzacja aplikacji API i Streamlit przy u≈ºyciu Docker, co u≈Çatwi wdra≈ºanie, zapewni powtarzalno≈õƒá ≈õrodowiska i skalowalno≈õƒá. Stworzymy Dockerfile i Docker Compose do konteneryzacji aplikacji.

    5. Orkiestracja z Kubernetes
       Opis: Orkiestracja skonteneryzowanej aplikacji przy u≈ºyciu Kubernetes, co zapewni wysokƒÖ dostƒôpno≈õƒá, skalowalno≈õƒá i automatyzacjƒô zarzƒÖdzania wdro≈ºeniami. Wdro≈ºenie aplikacji Docker na klaster Kubernetes i konfiguracja deployment√≥w, serwis√≥w i strategii skalowania.

    6. Monitoring i Wizualizacja Metryk z Prometheus i Grafana
       Opis: Wdro≈ºenie monitoringu i wizualizacji metryk systemu przy u≈ºyciu Prometheus i Grafana. Monitorowanie wydajno≈õci API, jako≈õci rekomendacji, wykorzystania zasob√≥w systemowych w celu ≈õledzenia dzia≈Çania, identyfikacji problem√≥w i zapewnienia zdrowia systemu.

    7. ≈öledzenie Eksperyment√≥w z MLflow
       Opis: Wdro≈ºenie MLflow do ≈õledzenia i zarzƒÖdzania eksperymentami ML, w tym tuningu parametr√≥w, wersjonowania modeli i zapewnienia powtarzalno≈õci eksperyment√≥w. Integracja MLflow do ≈õledzenia eksperyment√≥w fine-tuningu modeli, in≈ºynierii prompt√≥w i innych zada≈Ñ ML.




üöÄ PLAN ROZWOJU PROJEKTU - Product Recommendation System
üìã ROADMAP IMPLEMENTACJI NARZƒòDZI

FAZA 1: PODSTAWY DEVOPS (Fundamenty)
Cel: Przygotowanie infrastruktury dla dalszego rozwoju

1.1 Docker + Docker Compose ‚≠ê NAJWY≈ªSZY PRIORYTET
   Dockerfile dla FastAPI backend
   Dockerfile dla Streamlit frontend
   Dockerfile dla PostgreSQL database
   docker-compose.yml dla ca≈Çego stacku
   .dockerignore i optymalizacja obraz√≥w
   Dokumentacja setup'u

1.2 MLflow Integration ‚≠ê WYSOKI PRIORYTET
   Setup MLflow tracking server
   Integracja z model training pipeline
   Experiment logging w recommendation agent
   Model versioning i registry
   MLflow UI w docker-compose


FAZA 2: MONITORING & OBSERVABILITY
Cel: Implementacja monitoringu i zbierania metryk

2.1 Prometheus Setup
   Prometheus server w kontenerze
   Metryki z FastAPI (request count, latency, errors)
   Metryki z Streamlit (user interactions)
   System metrics (CPU, memory, disk)
   Custom business metrics (recommendation quality)

2.2 Grafana Integration
   Grafana server w kontenerze
   Dashboardy dla API metrics
   Dashboardy dla system health
   Alerting rules dla critical metrics
   Data source configuration (Prometheus)


FAZA 3: ORCHESTRATION & DEPLOYMENT
Cel: Production-ready deployment

3.1 Kubernetes Setup
   Local Kubernetes cluster (minikube/kind)
   Kubernetes manifests (deployments, services, configmaps)
   Ingress controller dla external access
   Persistent volumes dla databases
   Resource limits i health checks
   Horizontal Pod Autoscaler

3.2 CI/CD Pipeline (BONUS)
   GitHub Actions workflow
   Automated testing przed deployment
   Automated Docker image building
   Deployment do Kubernetes


FAZA 4: DATA ENGINEERING & AI ENHANCEMENT
Cel: Zaawansowane przetwarzanie danych i AI

4.1 Apache Airflow
   Airflow server w kontenerze
   DAG dla data preprocessing
   DAG dla model training/retraining
   DAG dla embeddings generation
   Monitoring Airflow jobs w Grafana

4.2 Simple RAG Implementation
   ChromaDB setup w kontenerze
   Fake knowledge base creation
   RAG node w LangGraph workflow
   Vector similarity search
   Enhanced prompts z RAG context

4.3 PySpark Integration (OPCJONALNE)
   PySpark cluster setup
   Migration similarity calculation do Spark
   Distributed embeddings processing
   Performance comparison z pandas


Na koniec przetestowaƒá dockera - nie zosta≈Çy wcze≈õniej przetestowane bo brak pamiƒôci na obrazy